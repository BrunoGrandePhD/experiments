{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MARGIN = 200\n",
    "MAX_ID = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "def get_seqs(chrom, pos, ref, alt, margin):\n",
    "    \"\"\"Obtain reference and alternate sequences \n",
    "    from Ensembl.\n",
    "    \n",
    "    Returns (ref_seq, alt_seq) tuple\n",
    "    \"\"\"\n",
    "    # Calculate start and end positions\n",
    "    start = pos - margin\n",
    "    end = pos + margin\n",
    "    # Construct the URL for the REST query\n",
    "    server = \"http://grch37.rest.ensembl.org/\"\n",
    "    ext = \"/sequence/region/human/{}:{}..{}:1?\".format(chrom, start, end)\n",
    "    # Send the HTTP request\n",
    "    r = requests.get(server+ext, headers={ \"Content-Type\" : \"text/plain\"})\n",
    "    # Extract reference sequence\n",
    "    ref_seq = str(r.text)\n",
    "    # Strip away any gaps when calculating length\n",
    "    ref_len = len(ref.strip(\"-\"))\n",
    "    alt_len = len(alt.strip(\"-\"))\n",
    "    # Categorize the variant\n",
    "    if ref_len < alt_len:  # Insertion\n",
    "        prefix = ref_seq[:margin+1]\n",
    "        suffix = ref_seq[margin+1:]\n",
    "        alt_seq = prefix + alt + suffix\n",
    "    elif ref_len > alt_len:  # Deletion\n",
    "        prefix = ref_seq[:margin]\n",
    "        suffix = ref_seq[margin+len(ref):]\n",
    "        alt_seq = prefix + suffix\n",
    "    else:  # SNP\n",
    "        prefix = ref_seq[:margin]\n",
    "        suffix = ref_seq[margin+1:]\n",
    "        alt_seq = prefix + alt + suffix\n",
    "    return ref_seq, alt_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "def print_results(results, headers=None):\n",
    "    \"\"\"Return results in pretty format\"\"\"\n",
    "    s_results = sorted(results.items(), key=lambda x: x[0])\n",
    "    if not headers:\n",
    "        headers = [\"\"] * (len(s_results[1]) + 1)\n",
    "    table = [[i] + [method[\"vaf\"] for method in result] for i, result in s_results]\n",
    "    print(table)\n",
    "    return tabulate(table, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parse indels file\n",
    "indels = {}\n",
    "headers = [\"id\", \"chrom\", \"start\", \"end\", \"ref\", \"alt\", \"ref_count\", \"alt_count\", \"vaf\"]\n",
    "with open(\"indels.txt\") as infile:\n",
    "    for line in infile:\n",
    "        # Parse line\n",
    "        indel = dict(zip(headers, line.rstrip(\"\\n\").split(\"\\t\")))\n",
    "        id_num = int(indel[\"id\"])\n",
    "        # Obtain sequences\n",
    "        ref_seq, alt_seq = get_seqs(indel[\"chrom\"], int(indel[\"start\"]), indel[\"ref\"], indel[\"alt\"], margin=MARGIN)\n",
    "        indel[\"ref_seq\"], indel[\"alt_seq\"] = ref_seq, alt_seq\n",
    "        # Store them for later\n",
    "        indels[id_num] = indel\n",
    "        # Limit number of indels for now\n",
    "        if id_num >= MAX_ID:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build dictionary of indels holding the values predicted by various methods\n",
    "# key: id\n",
    "# value: list of dict(ref_count, alt_count, amb_count, vaf) for each method\n",
    "results = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add original results from MAF file to results dict\n",
    "for i in range(1, MAX_ID):\n",
    "    # Iterate over reads\n",
    "    indel = indels[i]\n",
    "    results[indel[\"id\"]].append({\n",
    "            \"ref_count\": indel[\"ref_count\"],\n",
    "            \"alt_count\": indel[\"alt_count\"],\n",
    "            \"amb_count\": \"N/A\",\n",
    "            \"vaf\": indel[\"vaf\"]\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-mer Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some constants\n",
    "K = 10\n",
    "IVAL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rev_comp(seq):\n",
    "    \"\"\"Return reverse complement\"\"\"\n",
    "    cbases = {\"A\": \"T\",\n",
    "              \"T\": \"A\",\n",
    "              \"G\": \"C\",\n",
    "              \"C\": \"G\",\n",
    "              \"N\": \"N\"}\n",
    "    comp = \"\"\n",
    "    for base in seq[::-1]:\n",
    "        comp += cbases[base]\n",
    "    return comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmer_iter(text, k, step, ival):\n",
    "    \"\"\"Iterate over k-mers using the same \n",
    "    subsequence pattern.\n",
    "    \n",
    "    Returns generator.\n",
    "    \"\"\"\n",
    "    num_kmers = (len(text) - k * ival)//step + 1\n",
    "    for i in range(num_kmers):\n",
    "        kmer = text[i*step:i*step+k*ival:ival]\n",
    "        yield kmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_kmer_set(text, k, step, ival):\n",
    "    \"\"\"Generate set of k-mers from a given text\n",
    "    and its reverse complement.\n",
    "    \n",
    "    Returns set.\n",
    "    \"\"\"\n",
    "    kmers = set()\n",
    "    for kmer in kmer_iter(text, k, step, ival):\n",
    "        kmers.add(kmer)\n",
    "    comp = rev_comp(text)\n",
    "    for kmer in kmer_iter(comp, k, step, ival):\n",
    "        kmers.add(kmer)\n",
    "    return kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_score(text, kmer_set, k, step, ival):\n",
    "    \"\"\"Returns score for k-mers present\n",
    "    in the given k-mer set.\n",
    "    \n",
    "    Returns the count/score.\n",
    "    \"\"\"\n",
    "    kmer_count = 0\n",
    "    num_kmers = (len(text) - k)//step + 1\n",
    "    for kmer in kmer_iter(text, k, step, ival):\n",
    "        if kmer in kmer_set:\n",
    "            kmer_count += 1\n",
    "    return kmer_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1, MAX_ID):\n",
    "    # Iterate over reads\n",
    "    temp = \"reads/reads_{}.txt\"\n",
    "    with open(temp.format(i)) as reads:\n",
    "        ref_count = 0\n",
    "        alt_count = 0\n",
    "        amb_count = 0\n",
    "        indel = indels[i]\n",
    "        # Generate k-mers from sequences and store them for later\n",
    "        indel[\"ref_kmers\"] = get_kmer_set(indel[\"ref_seq\"], k=K, step=1, ival=IVAL)\n",
    "        indel[\"alt_kmers\"] = get_kmer_set(indel[\"alt_seq\"], k=K, step=1, ival=IVAL)\n",
    "        ref_kmers, alt_kmers = indel[\"ref_kmers\"], indel[\"alt_kmers\"]\n",
    "        # Iterate over reads\n",
    "        for read in reads:\n",
    "            read = read.rstrip(\"\\n\")\n",
    "            ref_score = calc_score(read, ref_kmers, k=K, step=2, ival=IVAL)\n",
    "            alt_score = calc_score(read, alt_kmers, k=K, step=2, ival=IVAL)\n",
    "            if ref_score > alt_score:\n",
    "                ref_count += 1\n",
    "            elif ref_score < alt_score:\n",
    "                alt_count += 1\n",
    "            else:\n",
    "                amb_count += 1\n",
    "        vaf = round(alt_count/(alt_count + ref_count), 2)\n",
    "        results[indel[\"id\"]].append({\n",
    "            \"ref_count\": ref_count,\n",
    "            \"alt_count\": alt_count,\n",
    "            \"amb_count\": amb_count,\n",
    "            \"vaf\": vaf\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Alignment Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet = ['A', 'C', 'G', 'T']\n",
    "score = [[0, 4, 2, 4, 8],\n",
    "         [4, 0, 4, 2, 8],\n",
    "         [2, 4, 0, 4, 8],\n",
    "         [4, 2, 4, 0, 8],\n",
    "         [8, 8, 8, 8, 8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def local_aln_score(t, p, offset=None):\n",
    "\n",
    "    # Create distance matrix\n",
    "    D = np.zeros((len(p)+1,len(t)+1), dtype=np.int)\n",
    "    \n",
    "    # Initialize first row\n",
    "    for i in range(1, len(t)+1):\n",
    "        D[0,i] = 0\n",
    "    \n",
    "    # Initialize first column\n",
    "    for i in range(1, len(p)+1):\n",
    "        D[i,0] = D[i-1,0] + score[alphabet.index(p[i-1])][-1]\n",
    "        \n",
    "    # Fill rest of the matrix\n",
    "    for i in range(1, len(p)+1):\n",
    "        for j in range(1, len(t)+1):\n",
    "            distHor = D[i,j-1] + score[-1][alphabet.index(t[j-1])]\n",
    "            distVer = D[i-1,j] + score[alphabet.index(p[i-1])][-1]\n",
    "            distDiag = D[i-1,j-1] + score[alphabet.index(p[i-1])][alphabet.index(t[j-1])]\n",
    "            D[i][j] = min(distHor, distVer, distDiag)\n",
    "    \n",
    "    # Return min of bottom row\n",
    "    return min(D[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1, MAX_ID):\n",
    "    # Iterate over reads\n",
    "    temp = \"reads/reads_{}.txt\"\n",
    "    with open(temp.format(i)) as reads:\n",
    "        ref_count = 0\n",
    "        alt_count = 0\n",
    "        amb_count = 0\n",
    "        indel = indels[i]\n",
    "        ref_kmers, alt_kmers = indel[\"ref_kmers\"], indel[\"alt_kmers\"]\n",
    "        for read in reads:\n",
    "            read = read.rstrip(\"\\n\")\n",
    "            ref_score = min(local_aln_score(ref_seq, read), local_aln_score(rev_comp(ref_seq), read))\n",
    "            alt_score = min(local_aln_score(alt_seq, read), local_aln_score(rev_comp(alt_seq), read))\n",
    "            if ref_score > alt_score:\n",
    "                ref_count += 1\n",
    "            elif ref_score < alt_score:\n",
    "                alt_count += 1\n",
    "            else:\n",
    "                amb_count += 1\n",
    "        if alt_count + ref_count == 0:\n",
    "            vaf = 0\n",
    "        else:\n",
    "            vaf = round(alt_count/(alt_count + ref_count), 2)\n",
    "        results[indel[\"id\"]].append({\n",
    "            \"ref_count\": ref_count,\n",
    "            \"alt_count\": alt_count,\n",
    "            \"amb_count\": amb_count,\n",
    "            \"vaf\": vaf\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', '0.35', 0.5, 0.73], ['2', '0', 0.0, 0.13]]\n",
      "  id    original    kmer    local_aln\n",
      "----  ----------  ------  -----------\n",
      "   1        0.35     0.5         0.73\n",
      "   2        0        0           0.13\n"
     ]
    }
   ],
   "source": [
    "print(print_results(results, headers=[\"id\", \"original\", \"kmer\", \"local_aln\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hybrid Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_kmer_idx(text, k, step, ival):\n",
    "    \"\"\"Generate a k-mer index from a given text\n",
    "    and its reverse complement.\n",
    "    \n",
    "    Returns index.\n",
    "    \"\"\"\n",
    "    kmer_idx = defaultdict(set)\n",
    "    for offset, kmer in enumerate(kmer_iter(text, k, step, ival)):\n",
    "        kmer_idx[kmer].add(offset)\n",
    "    return kmer_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_offset(p, kmer_idx, k, step, ival, min_support=3):\n",
    "    \"\"\"Find offset of pattern p in k-mer index.\n",
    "    \n",
    "    Returns offset as int.\n",
    "    \"\"\"\n",
    "    offset_support = defaultdict(int)\n",
    "    for pos, kmer in enumerate(kmer_iter(p, k, step, ival)):\n",
    "        offsets = kmer_idx[kmer] | kmer_idx[rev_comp(kmer)]\n",
    "        for offset in offsets:\n",
    "            offset_support[offset - pos] += 1\n",
    "        if any(map(lambda x: x >= min_support, offset_support.values())):\n",
    "            max_support = max(offset_support.values())\n",
    "            if offset_support.values().count(max_support) > 1:\n",
    "                continue\n",
    "            else:\n",
    "                idx = offset_support.values().index(max_support)\n",
    "                return offset_support[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1, MAX_ID): \n",
    "    # Iterate over reads\n",
    "    temp = \"reads/reads_{}.txt\"\n",
    "    with open(temp.format(i)) as reads:\n",
    "        ref_count = 0\n",
    "        alt_count = 0\n",
    "        amb_count = 0\n",
    "        indel = indels[i]\n",
    "        ref_kmer_idx = create_kmer_idx(indel[\"ref_seq\"], k=K, step=1, ival=IVAL)\n",
    "        alt_kmer_idx = create_kmer_idx(indel[\"alt_seq\"], k=K, step=1, ival=IVAL)\n",
    "        for read in reads:\n",
    "            read = read.rstrip(\"\\n\")\n",
    "            find_offset(read, ref_kmer_idx, k=K, step=1, ival=IVAL)\n",
    "#             ref_score = calc_score(read, ref_kmers, k=K, step=2, ival=IVAL)\n",
    "#             alt_score = calc_score(read, alt_kmers, k=K, step=2, ival=IVAL)\n",
    "#             if ref_score > alt_score:\n",
    "#                 ref_count += 1\n",
    "#             elif ref_score < alt_score:\n",
    "#                 alt_count += 1\n",
    "#             else:\n",
    "#                 amb_count += 1\n",
    "#         vaf = round(alt_count/(alt_count + ref_count), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
