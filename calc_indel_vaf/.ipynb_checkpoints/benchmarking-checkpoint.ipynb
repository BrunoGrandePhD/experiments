{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MARGIN = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "def get_seqs(chrom, pos, ref, alt, margin):\n",
    "    \"\"\"Obtain reference and alternate sequences \n",
    "    from Ensembl.\n",
    "    \n",
    "    Returns (ref_seq, alt_seq) tuple\n",
    "    \"\"\"\n",
    "    # Calculate start and end positions\n",
    "    start = pos - margin\n",
    "    end = pos + margin\n",
    "    # Construct the URL for the REST query\n",
    "    server = \"http://grch37.rest.ensembl.org/\"\n",
    "    ext = \"/sequence/region/human/{}:{}..{}:1?\".format(chrom, start, end)\n",
    "    # Send the HTTP request\n",
    "    r = requests.get(server+ext, headers={ \"Content-Type\" : \"text/plain\"})\n",
    "    # Extract reference sequence\n",
    "    ref_seq = str(r.text)\n",
    "    # Strip away any gaps when calculating length\n",
    "    ref_len = len(ref.strip(\"-\"))\n",
    "    alt_len = len(alt.strip(\"-\"))\n",
    "    # Categorize the variant\n",
    "    if ref_len < alt_len:  # Insertion\n",
    "        prefix = ref_seq[:margin+1]\n",
    "        suffix = ref_seq[margin+1:]\n",
    "        alt_seq = prefix + alt + suffix\n",
    "    elif ref_len > alt_len:  # Deletion\n",
    "        prefix = ref_seq[:margin]\n",
    "        suffix = ref_seq[margin+len(ref):]\n",
    "        alt_seq = prefix + suffix\n",
    "    else:  # SNP\n",
    "        prefix = ref_seq[:margin]\n",
    "        suffix = ref_seq[margin+1:]\n",
    "        alt_seq = prefix + alt + suffix\n",
    "    return ref_seq, alt_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-mer Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some constants\n",
    "K = 10\n",
    "IVAL = 2\n",
    "MAX_ID = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rev_comp(seq):\n",
    "    \"\"\"Return reverse complement\"\"\"\n",
    "    cbases = {\"A\": \"T\",\n",
    "              \"T\": \"A\",\n",
    "              \"G\": \"C\",\n",
    "              \"C\": \"G\",\n",
    "              \"N\": \"N\"}\n",
    "    comp = \"\"\n",
    "    for base in seq[::-1]:\n",
    "        comp += cbases[base]\n",
    "    return comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmer_iter(text, k, step, ival):\n",
    "    \"\"\"Iterate over k-mers using the same \n",
    "    subsequence pattern.\n",
    "    \n",
    "    Returns generator.\n",
    "    \"\"\"\n",
    "    num_kmers = (len(text) - k * ival)//step + 1\n",
    "    for i in range(num_kmers):\n",
    "        kmer = text[i*step:i*step+k*ival:ival]\n",
    "        yield kmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_kmer_set(text, k, step, ival):\n",
    "    \"\"\"Generate set of k-mers from a given text\n",
    "    and its reverse complement.\n",
    "    \n",
    "    Returns set.\n",
    "    \"\"\"\n",
    "    kmers = set()\n",
    "    for kmer in kmer_iter(text, k, step, ival):\n",
    "        kmers.add(kmer)\n",
    "    comp = rev_comp(text)\n",
    "    for kmer in kmer_iter(comp, k, step, ival):\n",
    "        kmers.add(kmer)\n",
    "    return kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_score(text, kmer_set, k, step, ival):\n",
    "    \"\"\"Returns score for k-mers present\n",
    "    in the given k-mer set.\n",
    "    \n",
    "    Returns the count/score.\n",
    "    \"\"\"\n",
    "    kmer_count = 0\n",
    "    num_kmers = (len(text) - k)//step + 1\n",
    "    for kmer in kmer_iter(text, k, step, ival):\n",
    "        if kmer in kmer_set:\n",
    "            kmer_count += 1\n",
    "    return kmer_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indels = {}\n",
    "headers = [\"id\", \"chrom\", \"start\", \"end\", \"ref\", \"alt\", \"ref_count\", \"alt_count\", \"vaf\"]\n",
    "with open(\"indels.txt\") as infile:\n",
    "    for line in infile:\n",
    "        # Parse line\n",
    "        indel = dict(zip(headers, line.rstrip(\"\\n\").split(\"\\t\")))\n",
    "        id_num = int(indel[\"id\"])\n",
    "        # Obtain sequences\n",
    "        ref_seq, alt_seq = get_seqs(indel[\"chrom\"], int(indel[\"start\"]), indel[\"ref\"], indel[\"alt\"], margin=MARGIN)\n",
    "        indel[\"ref_seq\"], indel[\"alt_seq\"] = ref_seq, alt_seq\n",
    "        # Generate k-mers from sequences\n",
    "        indel[\"ref_kmers\"] = get_kmer_set(ref_seq, k=K, step=1, ival=IVAL)\n",
    "        indel[\"alt_kmers\"] = get_kmer_set(alt_seq, k=K, step=1, ival=IVAL)\n",
    "        # Store them for later\n",
    "        indels[id_num] = indel\n",
    "        # Limit number of indels for now\n",
    "        if id_num >= MAX_ID:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        ref_count    before \t13\n",
      "                     after  \t15\n",
      "        alt_count    before \t7\n",
      "                     after  \t15\n",
      "        vaf          before \t0.35\n",
      "                     after  \t0.5\n",
      "        amb_count    before \tN/A\n",
      "                     after  \t13\n",
      "        \n",
      "\n",
      "        ref_count    before \t36\n",
      "                     after  \t33\n",
      "        alt_count    before \t0\n",
      "                     after  \t0\n",
      "        vaf          before \t0\n",
      "                     after  \t0.0\n",
      "        amb_count    before \tN/A\n",
      "                     after  \t9\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 2000):\n",
    "    # Iterate over reads\n",
    "    temp = \"reads/reads_{}.txt\"\n",
    "    with open(temp.format(i)) as reads:\n",
    "        ref_count = 0\n",
    "        alt_count = 0\n",
    "        amb_count = 0\n",
    "        indel = indels[i]\n",
    "        ref_kmers, alt_kmers = indel[\"ref_kmers\"], indel[\"alt_kmers\"]\n",
    "        for read in reads:\n",
    "            read = read.rstrip(\"\\n\")\n",
    "            ref_score = calc_score(read, ref_kmers, k=K, step=2, ival=IVAL)\n",
    "            alt_score = calc_score(read, alt_kmers, k=K, step=2, ival=IVAL)\n",
    "            if ref_score > alt_score:\n",
    "                ref_count += 1\n",
    "            elif ref_score < alt_score:\n",
    "                alt_count += 1\n",
    "            else:\n",
    "                amb_count += 1\n",
    "        vaf = round(alt_count/(alt_count + ref_count), 2)\n",
    "        output = \"\"\"\n",
    "        ref_count    before \\t{}\n",
    "                     after  \\t{}\n",
    "        alt_count    before \\t{}\n",
    "                     after  \\t{}\n",
    "        vaf          before \\t{}\n",
    "                     after  \\t{}\n",
    "        amb_count    before \\tN/A\n",
    "                     after  \\t{}\n",
    "        \"\"\".format(indel[\"ref_count\"], ref_count, indel[\"alt_count\"], alt_count, indel[\"vaf\"], vaf, amb_count)\n",
    "        print(output)\n",
    "    if i >= MAX_ID:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Alignment Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet = ['A', 'C', 'G', 'T']\n",
    "score = [[0, 4, 2, 4, 8],\n",
    "         [4, 0, 4, 2, 8],\n",
    "         [2, 4, 0, 4, 8],\n",
    "         [4, 2, 4, 0, 8],\n",
    "         [8, 8, 8, 8, 8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def local_aln_score(t, p):\n",
    "\n",
    "    # Create distance matrix\n",
    "    D = np.zeros((len(p)+1,len(t)+1), dtype=np.int)\n",
    "    \n",
    "    # Initialize first row\n",
    "    for i in range(1, len(t)+1):\n",
    "        D[0,i] = 0\n",
    "    \n",
    "    # Initialize first column\n",
    "    for i in range(1, len(p)+1):\n",
    "        D[i,0] = D[i-1,0] + score[alphabet.index(p[i-1])][-1]\n",
    "        \n",
    "    # Fill rest of the matrix\n",
    "    for i in range(1, len(p)+1):\n",
    "        for j in range(1, len(t)+1):\n",
    "            distHor = D[i,j-1] + score[-1][alphabet.index(t[j-1])]\n",
    "            distVer = D[i-1,j] + score[alphabet.index(p[i-1])][-1]\n",
    "            distDiag = D[i-1,j-1] + score[alphabet.index(p[i-1])][alphabet.index(t[j-1])]\n",
    "            D[i][j] = min(distHor, distVer, distDiag)\n",
    "    \n",
    "    # Return min of bottom row\n",
    "    return min(D[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        ref_count    before \t13\n",
      "                     after  \t11\n",
      "        alt_count    before \t7\n",
      "                     after  \t5\n",
      "        vaf          before \t0.35\n",
      "                     after  \t0.31\n",
      "        amb_count    before \tN/A\n",
      "                     after  \t27\n",
      "        \n",
      "\n",
      "        ref_count    before \t36\n",
      "                     after  \t0\n",
      "        alt_count    before \t0\n",
      "                     after  \t33\n",
      "        vaf          before \t0\n",
      "                     after  \t1.0\n",
      "        amb_count    before \tN/A\n",
      "                     after  \t9\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 2000):\n",
    "    # Iterate over reads\n",
    "    temp = \"reads/reads_{}.txt\"\n",
    "    with open(temp.format(i)) as reads:\n",
    "        ref_count = 0\n",
    "        alt_count = 0\n",
    "        amb_count = 0\n",
    "        indel = indels[i]\n",
    "        ref_kmers, alt_kmers = indel[\"ref_kmers\"], indel[\"alt_kmers\"]\n",
    "        for read in reads:\n",
    "            read = read.rstrip(\"\\n\")\n",
    "            ref_score = local_aln_score(ref_seq, read)\n",
    "            alt_score = local_aln_score(alt_seq, read)\n",
    "            if ref_score > alt_score:\n",
    "                ref_count += 1\n",
    "            elif ref_score < alt_score:\n",
    "                alt_count += 1\n",
    "            else:\n",
    "                amb_count += 1\n",
    "        vaf = round(alt_count/(alt_count + ref_count), 2)\n",
    "        output = \"\"\"\n",
    "        ref_count    before \\t{}\n",
    "                     after  \\t{}\n",
    "        alt_count    before \\t{}\n",
    "                     after  \\t{}\n",
    "        vaf          before \\t{}\n",
    "                     after  \\t{}\n",
    "        amb_count    before \\tN/A\n",
    "                     after  \\t{}\n",
    "        \"\"\".format(indel[\"ref_count\"], ref_count, indel[\"alt_count\"], alt_count, indel[\"vaf\"], vaf, amb_count)\n",
    "        print(output)\n",
    "    if i >= MAX_ID:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hybrid Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def create_kmer_idx(text, k, step, ival):\n",
    "    \"\"\"Generate a k-mer index from a given text\n",
    "    and its reverse complement.\n",
    "    \n",
    "    Returns index.\n",
    "    \"\"\"\n",
    "    kmer_idx = defaultdict(set)\n",
    "    for offset, kmer in enumerate(kmer_iter(text, k, step, ival)):\n",
    "        kmer_idx[kmer].add(offset)\n",
    "    return kmer_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_offset(p, kmer_idx, k, step, ival, min_support=2):\n",
    "    \"\"\"Find offset of pattern p in k-mer index.\n",
    "    \n",
    "    Returns offset as int.\n",
    "    \"\"\"\n",
    "    offset_support = defaultdict(int)\n",
    "    for kmer in kmer_iter(p, k, step, ival):\n",
    "        offsets = kmer_idx[kmer] + kmer_idx[rev_comp(kmer)]\n",
    "        for offset in offsets:\n",
    "            offset_support[offset] += 1\n",
    "        print(offset_support)\n",
    "        if any(map(lambda x: x > min_support, offset_support.values())):\n",
    "            max_support = max(offset_support.values())\n",
    "            if offset_support.values().count(max_support) > 1:\n",
    "                continue\n",
    "            else:\n",
    "                idx = offset_support.values().index(max_support)\n",
    "                return offset_support[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, 2000):\n",
    "    # Iterate over reads\n",
    "    temp = \"reads/reads_{}.txt\"\n",
    "    with open(temp.format(i)) as reads:\n",
    "        ref_count = 0\n",
    "        alt_count = 0\n",
    "        amb_count = 0\n",
    "        indel = indels[i]\n",
    "        ref_kmers, alt_kmers = indel[\"ref_kmers\"], indel[\"alt_kmers\"]\n",
    "        for read in reads:\n",
    "            read = read.rstrip(\"\\n\")\n",
    "            ref_score = calc_score(read, ref_kmers, k=K, step=2, ival=IVAL)\n",
    "            alt_score = calc_score(read, alt_kmers, k=K, step=2, ival=IVAL)\n",
    "            if ref_score > alt_score:\n",
    "                ref_count += 1\n",
    "            elif ref_score < alt_score:\n",
    "                alt_count += 1\n",
    "            else:\n",
    "                amb_count += 1\n",
    "        vaf = round(alt_count/(alt_count + ref_count), 2)\n",
    "        output = \"\"\"\n",
    "        ref_count    before \\t{}\n",
    "                     after  \\t{}\n",
    "        alt_count    before \\t{}\n",
    "                     after  \\t{}\n",
    "        vaf          before \\t{}\n",
    "                     after  \\t{}\n",
    "        amb_count    before \\tN/A\n",
    "                     after  \\t{}\n",
    "        \"\"\".format(indel[\"ref_count\"], ref_count, indel[\"alt_count\"], alt_count, indel[\"vaf\"], vaf, amb_count)\n",
    "        print(output)\n",
    "    if i >= MAX_ID:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
